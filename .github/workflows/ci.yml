name: PXF CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  build_gpdb_debs:
    name: Build open-gpdb Debian Packages
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        target: # make targets
          - 'deb-gpdb-bionic'
          - 'deb-gpdb-jammy'
          - 'deb-cbdb-jammy'
    steps:
      - name: Get Date
        id: get-date
        run: echo "week=$(/bin/date -u '+%U')" >> "$GITHUB_OUTPUT"
      - name: database deb files caching
        id: cache-debs
        uses: actions/cache@v4
        with:
          path: ./downloads/*.deb
          # save per-os with 7 days TTL
          key: ${{ runner.os }}-${{ matrix.target }}-${{ steps.get-date.outputs.week }}

      - name: Checkout code
        uses: actions/checkout@v4
        with:
          submodules: true

      - name: Build open-gpdb / cloudberry
        if: steps.cache-debs.outputs.cache-hit != 'true'
        run: make -C package ${{ matrix.target }}

  build_pxf_debs:
    name: Build PXF Debian Packages
    runs-on: ubuntu-latest
    needs: [build_gpdb_debs]
    strategy:
      fail-fast: false
      matrix:
        target: # make targets
          - pxf: 'deb-pxf6-gpdb-bionic'
            db-cache-key-sfx: 'deb-gpdb-bionic'
          - pxf: 'deb-pxf6-gpdb-jammy'
            db-cache-key-sfx: 'deb-gpdb-jammy'
          - pxf: 'deb-pxf6-cbdb-jammy'
            db-cache-key-sfx: 'deb-cbdb-jammy'
    steps:
      - name: Get Date
        id: get-date
        run: echo "week=$(/bin/date -u '+%U')" >> "$GITHUB_OUTPUT"

      - name: Checkout code
        uses: actions/checkout@v4
        with:
          submodules: true

      - name: (restore) database deb files caching
        id: cache-debs
        uses: actions/cache/restore@v4
        with:
          fail-on-cache-miss: true
          path: ./downloads/*.deb
          key: ${{ runner.os }}-${{ matrix.target.db-cache-key-sfx }}-${{ steps.get-date.outputs.week }}

      - name: Build PXF6
        run: make -C package ${{ matrix.target.pxf }}

      - name: (save) PXF debs in cache
        uses: actions/cache/save@v4
        id: cache
        with:
            path: ./downloads/*pxf*.deb
            key: ${{ runner.os }}-${{ matrix.target.pxf }}-${{ github.sha }}

  use_pxf_debs:
    name: Automation tests
    runs-on: ubuntu-latest
    needs: [build_pxf_debs]
    strategy:
      fail-fast: false
      matrix:
        target:
          - pxf: 'deb-pxf6-gpdb-bionic'
            db-cache-key-sfx: 'deb-gpdb-bionic'
          - pxf: 'deb-pxf6-gpdb-jammy'
            db-cache-key-sfx: 'deb-gpdb-jammy'
          - pxf: 'deb-pxf6-cbdb-jammy'
            db-cache-key-sfx: 'deb-cbdb-jammy'
    steps:
      - name: Get Date
        id: get-date
        run: echo "week=$(/bin/date -u '+%U')" >> "$GITHUB_OUTPUT"

      - name: Checkout code
        uses: actions/checkout@v4
        with:
          submodules: true

      - name: (restore) database deb files caching
        id: cache-debs-db
        uses: actions/cache/restore@v4
        with:
          fail-on-cache-miss: true
          path: ./downloads/*.deb
          key: ${{ runner.os }}-${{ matrix.target.db-cache-key-sfx }}-${{ steps.get-date.outputs.week }}

      - name: (restore) PXF deb files caching
        id: cache-debs-pxf
        uses: actions/cache/restore@v4
        with:
          fail-on-cache-miss: true
          path: ./downloads/*pxf*.deb
          key: ${{ runner.os }}-${{ matrix.target.pxf }}-${{ github.sha }}

      - name: Use PXF builds
        run: ls -lah ./downloads/

      - name: Build automation images
        if: matrix.target.pxf == 'deb-pxf6-gpdb-bionic'  # FIXME: support other PXF versions
        run: |
          echo "Building automation images..."
          cd automation
          make copy-debs
          docker compose build
          docker compose up

      - name: Extract test artifacts from container
        if: always()
        run: |
          echo "Extracting test artifacts from container..."
          
          # Create test artifacts directory structure
          mkdir -p ./automation/test_artifacts/surefire-reports
          mkdir -p ./automation/test_artifacts/automation_logs
          mkdir -p ./automation/test_artifacts/pxf_regress
          
          # Extract main test reports with preserved structure
          docker compose -f automation/docker-compose.yml cp universe:/home/gpadmin/workspace/pxf/automation/target/surefire-reports ./automation/test_artifacts || echo "No surefire-reports found"
          docker compose -f automation/docker-compose.yml cp universe:/home/gpadmin/workspace/pxf/automation/automation_logs ./automation/test_artifacts || echo "No automation_logs found"
          
          # Extract additional test results for debugging with preserved structure
          docker compose -f automation/docker-compose.yml cp universe:/home/gpadmin/workspace/pxf/automation/pxf_regress ./automation/test_artifacts || echo "No pxf_regress found"
          
          echo "Extracted artifacts:"
          ls -la ./automation/test_artifacts/ || echo "No test_artifacts directory"

      - name: Save automation artifacts
        if: always()
        uses: actions/upload-artifact@v4
        id: upload_automation_step
        with:
          name: automation-test-results-${{ matrix.target.pxf }}
          path: |
            ./automation/test_artifacts/surefire-reports
            ./automation/test_artifacts/automation_logs
            ./automation/test_artifacts/pxf_regress
            ./automation/test_artifacts/sqlrepo
          retention-days: 30

      - name: Process TestNG reports
        if: success() || failure()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            
            const targetPlatform = '${{ matrix.target.pxf }}';
            const testReportsDir = './automation/test_artifacts/surefire-reports';
            
            console.log(`Processing test reports for ${targetPlatform}...`);
            
            // Start building the step summary
            const summary = core.summary
              .addHeading(`Test Results Summary for ${targetPlatform}`)
              .addHeading('ðŸ“¦ Artifacts', 3)
              .addLink('Raw Test Results', "${{ steps.upload_automation_step.outputs.artifact-url }}");
            
            let hasErrors = false;
            
            // Check if test reports exist
            if (!fs.existsSync(testReportsDir)) {
              core.error(`No test reports found for ${targetPlatform}`);
              summary.addRaw('No test reports available\n\n');
              hasErrors = true;
            }
            
            // Process TestNG XML results
            const testngResultsPath = path.join(testReportsDir, 'testng-results.xml');
            if (!fs.existsSync(testngResultsPath)) {
              core.error('No testng-results.xml found');
              summary.addRaw('No TestNG results file found\n\n');
              hasErrors = true;
            }
            
            if (hasErrors) {
              // Write to step summary
              await summary.write();
            
              // Exit with error code if there were errors
              process.exit(1);
            }
            try {
              const xmlContent = fs.readFileSync(testngResultsPath, 'utf8');
            
              // Extract test statistics using regex
              const totalMatch = xmlContent.match(/total="(\d+)"/);
              const passedMatch = xmlContent.match(/passed="(\d+)"/);
              const failedMatch = xmlContent.match(/failed="(\d+)"/);
              const skippedMatch = xmlContent.match(/skipped="(\d+)"/);
            
              const total = totalMatch ? totalMatch[1] : '0';
              const passed = passedMatch ? passedMatch[1] : '0';
              const failed = failedMatch ? failedMatch[1] : '0';
              const skipped = skippedMatch ? skippedMatch[1] : '0';
            
              // Add test statistics to summary
              summary
                .addRaw(`\n\nTest Results for ${targetPlatform}:\n\n`)
                .addRaw(`Total: ${total}\n\n`)
                .addRaw(`Passed: ${passed}\n\n`)
                .addRaw(`Failed: ${failed}\n\n`)
                .addRaw(`Skipped: ${skipped}\n\n`)
            
              // Check if there are failed or skipped tests
              const failedCount = parseInt(failed) || 0;
              const skippedCount = parseInt(skipped) || 0;
            
              if (failedCount > 0) {
                core.error(`Test execution failed: ${failedCount} test(s) failed`);
                hasErrors = true;
              }
              if (skippedCount > 0) {
                core.error(`Test execution incomplete: ${skippedCount} test(s) skipped`);
                hasErrors = true;
              }
            } catch (error) {
              console.log('Error processing TestNG results:', error.message);
              core.error('Error processing test results');
              hasErrors = true;
            }
            
            // Write to step summary
            await summary.write();
            
            // Exit with error code if there were errors
            if (hasErrors) {
              process.exit(1);
            }

        # TODO: add /regression and /automation tests here
