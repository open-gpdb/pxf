name: PXF CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  build_gpdb_debs:
    name: Build open-gpdb Debian Packages
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        target: # make targets
          - 'deb-gpdb-bionic'
          - 'deb-gpdb-jammy'
          - 'deb-cbdb-jammy'
    steps:
      - name: Get Date
        id: get-date
        run: echo "week=$(/bin/date -u '+%U')" >> "$GITHUB_OUTPUT"
      - name: database deb files caching
        id: cache-debs
        uses: actions/cache@v4
        with:
          path: ./downloads/*.deb
          # save per-os with 7 days TTL
          key: ${{ runner.os }}-${{ matrix.target }}-${{ steps.get-date.outputs.week }}

      - name: Checkout code
        uses: actions/checkout@v4
        with:
          submodules: true

      - name: Build open-gpdb / cloudberry
        if: steps.cache-debs.outputs.cache-hit != 'true'
        run: make -C package ${{ matrix.target }}

  build_pxf_debs:
    name: Build PXF Debian Packages
    runs-on: ubuntu-latest
    needs: [build_gpdb_debs]
    strategy:
      fail-fast: false
      matrix:
        target: # make targets
          - pxf: 'deb-pxf6-gpdb-bionic'
            db-cache-key-sfx: 'deb-gpdb-bionic'
          - pxf: 'deb-pxf6-gpdb-jammy'
            db-cache-key-sfx: 'deb-gpdb-jammy'
          - pxf: 'deb-pxf6-cbdb-jammy'
            db-cache-key-sfx: 'deb-cbdb-jammy'
    steps:
      - name: Get Date
        id: get-date
        run: echo "week=$(/bin/date -u '+%U')" >> "$GITHUB_OUTPUT"

      - name: Checkout code
        uses: actions/checkout@v4
        with:
          submodules: true

      - name: (restore) database deb files caching
        id: cache-debs
        uses: actions/cache/restore@v4
        with:
          fail-on-cache-miss: true
          path: ./downloads/*.deb
          key: ${{ runner.os }}-${{ matrix.target.db-cache-key-sfx }}-${{ steps.get-date.outputs.week }}

      - name: Build PXF6
        run: make -C package ${{ matrix.target.pxf }}

      - name: (save) PXF debs in cache
        uses: actions/cache/save@v4
        id: cache
        with:
            path: ./downloads/*pxf*.deb
            key: ${{ runner.os }}-${{ matrix.target.pxf }}-${{ github.sha }}

  use_pxf_debs:
    name: Automation tests
    runs-on: ubuntu-latest
    needs: [build_pxf_debs]
    strategy:
      fail-fast: false
      matrix:
        target:
          - pxf: 'deb-pxf6-gpdb-bionic'
            db-cache-key-sfx: 'deb-gpdb-bionic'
          - pxf: 'deb-pxf6-gpdb-jammy'
            db-cache-key-sfx: 'deb-gpdb-jammy'
          - pxf: 'deb-pxf6-cbdb-jammy'
            db-cache-key-sfx: 'deb-cbdb-jammy'
    steps:
      - name: Get Date
        id: get-date
        run: echo "week=$(/bin/date -u '+%U')" >> "$GITHUB_OUTPUT"

      - name: Checkout code
        uses: actions/checkout@v4
        with:
          submodules: true

      - name: (restore) database deb files caching
        id: cache-debs-db
        uses: actions/cache/restore@v4
        with:
          fail-on-cache-miss: true
          path: ./downloads/*.deb
          key: ${{ runner.os }}-${{ matrix.target.db-cache-key-sfx }}-${{ steps.get-date.outputs.week }}

      - name: (restore) PXF deb files caching
        id: cache-debs-pxf
        uses: actions/cache/restore@v4
        with:
          fail-on-cache-miss: true
          path: ./downloads/*pxf*.deb
          key: ${{ runner.os }}-${{ matrix.target.pxf }}-${{ github.sha }}

      - name: Use PXF builds
        run: ls -lah ./downloads/

      - name: Build automation images
        if: matrix.target.pxf == 'deb-pxf6-gpdb-bionic'  # FIXME: support other PXF versions
        run: |
          echo "Building automation images..."
          cd automation
          make copy-debs
          docker compose build
          docker compose up

      - name: Save automation artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: automation-test-results-${{ matrix.target.pxf }}
          path: |
            /home/gpadmin/workspace/pxf/automation/target/surefire-reports
            /home/gpadmin/workspace/pxf/automation/automation_logs
          retention-days: 30

      - name: Process TestNG reports
        if: success() || failure()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            
            const targetPlatform = '${{ matrix.target.pxf }}';
            const testReportsDir = '/home/gpadmin/workspace/pxf/automation/target/surefire-reports';
            
            console.log(`Processing test reports for ${targetPlatform}...`);
            
            // Start building the step summary
            const summary = core.summary
              .addHeading(`Test Results Summary for ${targetPlatform}`)
              .addHeading('ðŸ“¦ Artifacts', 3)
              .addRaw(`- [Raw Test Results](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts) - automation-test-results-${targetPlatform}\n\n`);
            
            // Check if test reports exist
            if (!fs.existsSync(testReportsDir)) {
              core.setFailed(`No test reports found for ${targetPlatform}`);
              summary.addRaw('No test reports available\n\n');
              summary.write();
              return;
            }
            
            // Process TestNG XML results
            const testngResultsPath = path.join(testReportsDir, 'testng-results.xml');
            if (!fs.existsSync(testngResultsPath)) {
              core.setFailed('No testng-results.xml found');
              summary.addRaw('No TestNG results file found\n\n');
              summary.write();
              return;
            }
            
            try {
              const xmlContent = fs.readFileSync(testngResultsPath, 'utf8');
            
              // Extract test statistics using regex
              const totalMatch = xmlContent.match(/total="(\d+)"/);
              const passedMatch = xmlContent.match(/passed="(\d+)"/);
              const failedMatch = xmlContent.match(/failed="(\d+)"/);
              const skippedMatch = xmlContent.match(/skipped="(\d+)"/);
            
              const total = totalMatch ? totalMatch[1] : '0';
              const passed = passedMatch ? passedMatch[1] : '0';
              const failed = failedMatch ? failedMatch[1] : '0';
              const skipped = skippedMatch ? skippedMatch[1] : '0';
            
              // Add test statistics to summary
              summary
                .addRaw('```\n')
                .addRaw(`Test Results for ${targetPlatform}:\n`)
                .addRaw(`Total: ${total}\n`)
                .addRaw(`Passed: ${passed}\n`)
                .addRaw(`Failed: ${failed}\n`)
                .addRaw(`Skipped: ${skipped}\n`)
                .addRaw('```\n\n');
            
              // Fail step if there are failed or skipped tests
              const failedCount = parseInt(failed) || 0;
              const skippedCount = parseInt(skipped) || 0;
            
              if (failedCount > 0) {
                core.setFailed(`Test execution failed: ${failedCount} test(s) failed`);
              } else if (skippedCount > 0) {
                core.setFailed(`Test execution incomplete: ${skippedCount} test(s) skipped`);
              }
            } catch (error) {
              console.log('Error processing TestNG results:', error.message);
              core.setFailed('Error processing test results\n\n');
            }
            
            // Check if HTML report exists and add link
            const htmlReportPath = path.join(testReportsDir, 'index.html');
            if (fs.existsSync(htmlReportPath)) {
              summary.addRaw(`ðŸ“Š [View Detailed Test Report](${htmlReportPath})\n\n`);
            }
            
            // Write to step summary
            summary.write();

        # TODO: add /regression and /automation tests here
